{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA on Tweets Based On USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T08:17:23.375068Z",
     "start_time": "2020-12-20T08:17:20.864237Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reviews_datasets = pd.read_csv(r'C:\\Debjit\\ISB\\03_Term-2\\Foundational Project\\Data Dump\\CleanTweets\\FP1_Merged_US_Sentiments.csv')\n",
    "reviews_datasets = reviews_datasets.head(20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T08:18:31.841361Z",
     "start_time": "2020-12-20T08:18:31.838372Z"
    }
   },
   "outputs": [],
   "source": [
    "###cleaning tweets via function\n",
    "import re\n",
    "def clean_tweet(clean_txt):\n",
    "    text = re.sub(\"RT @[\\w]*:\",\"\",clean_txt)\n",
    "    text = re.sub(\"@[\\w]*\",\"\",clean_txt)\n",
    "    text = re.sub(\"https?://[A-Za-z0-9./]*\",\"\",clean_txt)\n",
    "    text = re.sub(\"\\n\",\"\",clean_txt)\n",
    "    return clean_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T08:18:33.508119Z",
     "start_time": "2020-12-20T08:18:32.653304Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>truncated</th>\n",
       "      <th>url</th>\n",
       "      <th>location_US_State</th>\n",
       "      <th>geo_US_State</th>\n",
       "      <th>place_US_State</th>\n",
       "      <th>createDate</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>TB_polarity</th>\n",
       "      <th>TB_subjectivity</th>\n",
       "      <th>AF_polarity</th>\n",
       "      <th>TB_sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217234682309464064</td>\n",
       "      <td>2020-01-14T23:58:58</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1217197393948692482</td>\n",
       "      <td>2020-01-14T21:30:47</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2 things are often true there is enough evide...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2 things are often true there is enough evide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217197457270104066</td>\n",
       "      <td>2020-01-14T21:31:02</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/5R55ma3Efz]</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Whether you are a Democrat or Republican Trump...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Whether you are a Democrat or Republican Trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1217197459857866753</td>\n",
       "      <td>2020-01-14T21:31:03</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>pubs You don t say Trump Adviser Caught on Ta...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>pubs You don t say Trump Adviser Caught on Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1217197467441213441</td>\n",
       "      <td>2020-01-14T21:31:05</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>So the shooting in Pensacola WAS a terrorist ...</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>Strongly Negative</td>\n",
       "      <td>So the shooting in Pensacola WAS a terrorist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1323233360060317698</td>\n",
       "      <td>2020-11-02T11:59:52</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>The only economic agrument the haters have fou...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>The only economic agrument the haters have fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1323233426070216705</td>\n",
       "      <td>2020-11-02T12:00:07</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>Im proud to be a hispanic American i studied ...</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.435417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Im proud to be a hispanic American i studied ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1323233440980856834</td>\n",
       "      <td>2020-11-02T12:00:11</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>Prediction after loses next week he will quit...</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Prediction after loses next week he will quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1323233119793827842</td>\n",
       "      <td>2020-11-02T11:58:54</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>They gotta shut down his Twitter Trump</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>They gotta shut down his Twitter Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1323234083107987465</td>\n",
       "      <td>2020-11-02T12:02:44</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>I just saw a television advertisement by Trum...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I just saw a television advertisement by Trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           created_at  truncated  \\\n",
       "0      1217234682309464064  2020-01-14T23:58:58      False   \n",
       "1      1217197393948692482  2020-01-14T21:30:47      False   \n",
       "2      1217197457270104066  2020-01-14T21:31:02       True   \n",
       "3      1217197459857866753  2020-01-14T21:31:03      False   \n",
       "4      1217197467441213441  2020-01-14T21:31:05      False   \n",
       "...                    ...                  ...        ...   \n",
       "19995  1323233360060317698  2020-11-02T11:59:52      False   \n",
       "19996  1323233426070216705  2020-11-02T12:00:07      False   \n",
       "19997  1323233440980856834  2020-11-02T12:00:11      False   \n",
       "19998  1323233119793827842  2020-11-02T11:58:54      False   \n",
       "19999  1323234083107987465  2020-11-02T12:02:44      False   \n",
       "\n",
       "                             url         location_US_State geo_US_State  \\\n",
       "0                             []             New Hampshire          NaN   \n",
       "1                             []                   Florida          NaN   \n",
       "2      [https://t.co/5R55ma3Efz]                New Jersey          NaN   \n",
       "3                             []                  Virginia          NaN   \n",
       "4                             []                     Texas          NaN   \n",
       "...                          ...                       ...          ...   \n",
       "19995                         []                  Delaware          NaN   \n",
       "19996                         []             Massachusetts          NaN   \n",
       "19997                         []  United States of America          NaN   \n",
       "19998                         []                   Georgia          NaN   \n",
       "19999                         []                  Maryland          NaN   \n",
       "\n",
       "      place_US_State  createDate  \\\n",
       "0                NaN  2020-01-14   \n",
       "1                NaN  2020-01-14   \n",
       "2                NaN  2020-01-14   \n",
       "3                NaN  2020-01-14   \n",
       "4                NaN  2020-01-14   \n",
       "...              ...         ...   \n",
       "19995            NaN  2020-11-02   \n",
       "19996            NaN  2020-11-02   \n",
       "19997            NaN  2020-11-02   \n",
       "19998            NaN  2020-11-02   \n",
       "19999            NaN  2020-11-02   \n",
       "\n",
       "                                               clean_txt  TB_polarity  \\\n",
       "0       A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...     0.200000   \n",
       "1       2 things are often true there is enough evide...     0.450000   \n",
       "2      Whether you are a Democrat or Republican Trump...     0.000000   \n",
       "3       pubs You don t say Trump Adviser Caught on Ta...     0.000000   \n",
       "4       So the shooting in Pensacola WAS a terrorist ...    -0.800000   \n",
       "...                                                  ...          ...   \n",
       "19995  The only economic agrument the haters have fou...     0.050000   \n",
       "19996   Im proud to be a hispanic American i studied ...     0.177083   \n",
       "19997   Prediction after loses next week he will quit...    -0.150000   \n",
       "19998            They gotta shut down his Twitter Trump     -0.155556   \n",
       "19999   I just saw a television advertisement by Trum...     0.000000   \n",
       "\n",
       "       TB_subjectivity  AF_polarity       TB_sentiment  \\\n",
       "0             0.200000         -5.0            Neutral   \n",
       "1             0.716667          5.0           Positive   \n",
       "2             0.000000          1.0            Neutral   \n",
       "3             0.000000         -2.0            Neutral   \n",
       "4             1.000000         -3.0  Strongly Negative   \n",
       "...                ...          ...                ...   \n",
       "19995         0.400000         -3.0            Neutral   \n",
       "19996         0.435417          1.0            Neutral   \n",
       "19997         0.050000          3.0            Neutral   \n",
       "19998         0.288889          0.0            Neutral   \n",
       "19999         0.000000          0.0            Neutral   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0       A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...  \n",
       "1       2 things are often true there is enough evide...  \n",
       "2      Whether you are a Democrat or Republican Trump...  \n",
       "3       pubs You don t say Trump Adviser Caught on Ta...  \n",
       "4       So the shooting in Pensacola WAS a terrorist ...  \n",
       "...                                                  ...  \n",
       "19995  The only economic agrument the haters have fou...  \n",
       "19996   Im proud to be a hispanic American i studied ...  \n",
       "19997   Prediction after loses next week he will quit...  \n",
       "19998            They gotta shut down his Twitter Trump   \n",
       "19999   I just saw a television advertisement by Trum...  \n",
       "\n",
       "[20000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned tweets\n",
    "reviews_datasets['clean_txt'] = reviews_datasets['clean_txt'].apply(lambda x: clean_tweet(x))\n",
    "reviews_datasets.head(20)\n",
    "\n",
    "reviews_datasets['clean_tweet'] = reviews_datasets.clean_txt.apply(clean_tweet)\n",
    "reviews_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T08:18:52.075928Z",
     "start_time": "2020-12-20T08:18:35.117346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 134032 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating vocabulary of all the words in tweets data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "vectorizer = CountVectorizer(\n",
    "analyzer='word',       \n",
    "min_df=3,# minimum required occurences of a word \n",
    "stop_words='english',# remove stop words\n",
    "lowercase=True,# convert all words to lowercase\n",
    "token_pattern='[a-zA-Z0-9]{3,}',# num chars > 3\n",
    "max_features=5000,# max number of unique words\n",
    "                            )\n",
    "data_matrix = vectorizer.fit_transform(reviews_datasets.clean_txt)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T08:19:27.846249Z",
     "start_time": "2020-12-20T08:18:54.701402Z"
    }
   },
   "outputs": [],
   "source": [
    "#LDA to create topics along with the probability distribution for each word in our vocabulary for each topic\n",
    "lda_model = LatentDirichletAllocation(\n",
    "n_components=10, # Number of topics\n",
    "learning_method='online',\n",
    "random_state=20,       \n",
    "n_jobs = -1  # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T09:30:15.795829Z",
     "start_time": "2020-12-20T09:30:15.781745Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-09db8c12d193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#creating web based visualization for the topic from LDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tsne'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "#creating web based visualization for the topic from LDA\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_model, data_matrix, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['party', 'working', 'country', 'left', 'free', 'news', 'did', 'democrats', 'americans', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['votes', 'time', 'america', 'usa', 'clear', 'electionday', 'like', 'just', 'vote', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['won', 'world', 'miami', 'covid', 'presidential', '000', 'think', 'voters', 'know', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['violence', 'president', 'maga2020', 'love', 'trump2020landslide', 'china', 'loses', 'donald', 'maga', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['listen', 'win', 'does', 'trump2020', 'don', 'biden', 'make', 'media', 'election2020', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['joe', '2020', 'live', 'new', 'america', 'president', 'rally', 'biden', 'election', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['come', 'trump2020landslidevictory', 'say', 'voting', 'obama', 'american', 'going', 'trump', 'true', 'people']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['post', 'nigeria', 'cartoon', 'rallies', 'lose', 'people', 'day', 'state', 'trump', 'amp']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['florida', 'good', 'man', 'voted', 'trumpcollapse', 'biden', 'years', 'winner', 'night', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['lies', 'old', 'convoy', 'government', 'covid19', 'don', 'right', 'uselections2020', 'let', 'trump']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#top 10 words in each topic\n",
    "for i,topic in enumerate(lda_model.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>truncated</th>\n",
       "      <th>url</th>\n",
       "      <th>location_US_State</th>\n",
       "      <th>geo_US_State</th>\n",
       "      <th>place_US_State</th>\n",
       "      <th>createDate</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>TB_polarity</th>\n",
       "      <th>TB_subjectivity</th>\n",
       "      <th>AF_polarity</th>\n",
       "      <th>TB_sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217234689376837633</td>\n",
       "      <td>2020-01-14T23:58:59</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Justin Trudeau blames escalation between Trum...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Justin Trudeau blames escalation between Trum...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1217196269912772608</td>\n",
       "      <td>2020-01-14T21:26:19</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Mini Mike Bloomberg is self made no 400 mil i...</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Mini Mike Bloomberg is self made no 400 mil i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217196265295024128</td>\n",
       "      <td>2020-01-14T21:26:18</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/YK6nz8VuFV]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Absolutely Now when it comes to selling arms ...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Absolutely Now when it comes to selling arms ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1217196230926897153</td>\n",
       "      <td>2020-01-14T21:26:10</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>pubs You don t say Trump Adviser Caught on Ta...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>pubs You don t say Trump Adviser Caught on Ta...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1217196220579565569</td>\n",
       "      <td>2020-01-14T21:26:08</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2 things are often true there is enough evide...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2 things are often true there is enough evide...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  truncated  \\\n",
       "0  1217234689376837633  2020-01-14T23:58:59      False   \n",
       "1  1217196269912772608  2020-01-14T21:26:19      False   \n",
       "2  1217196265295024128  2020-01-14T21:26:18       True   \n",
       "3  1217196230926897153  2020-01-14T21:26:10      False   \n",
       "4  1217196220579565569  2020-01-14T21:26:08      False   \n",
       "\n",
       "                         url  location_US_State  geo_US_State  place_US_State  \\\n",
       "0                         []                NaN           NaN             NaN   \n",
       "1                         []                NaN           NaN             NaN   \n",
       "2  [https://t.co/YK6nz8VuFV]                NaN           NaN             NaN   \n",
       "3                         []                NaN           NaN             NaN   \n",
       "4                         []                NaN           NaN             NaN   \n",
       "\n",
       "   createDate                                          clean_txt  TB_polarity  \\\n",
       "0  2020-01-14   Justin Trudeau blames escalation between Trum...         0.00   \n",
       "1  2020-01-14   Mini Mike Bloomberg is self made no 400 mil i...        -0.35   \n",
       "2  2020-01-14   Absolutely Now when it comes to selling arms ...         0.10   \n",
       "3  2020-01-14   pubs You don t say Trump Adviser Caught on Ta...         0.00   \n",
       "4  2020-01-14   2 things are often true there is enough evide...         0.45   \n",
       "\n",
       "   TB_subjectivity  AF_polarity TB_sentiment  \\\n",
       "0         0.000000         -6.0      Neutral   \n",
       "1         0.800000          2.0     Negative   \n",
       "2         0.500000          3.0      Neutral   \n",
       "3         0.000000         -2.0      Neutral   \n",
       "4         0.716667          5.0     Positive   \n",
       "\n",
       "                                         clean_tweet  Topic  \n",
       "0   Justin Trudeau blames escalation between Trum...      7  \n",
       "1   Mini Mike Bloomberg is self made no 400 mil i...      4  \n",
       "2   Absolutely Now when it comes to selling arms ...      9  \n",
       "3   pubs You don t say Trump Adviser Caught on Ta...      9  \n",
       "4   2 things are often true there is enough evide...      6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assigning topic to each Tweet\n",
    "topic_values = lda_model.transform(data_matrix)\n",
    "reviews_datasets['Topic'] = topic_values.argmax(axis=1)\n",
    "reviews_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
