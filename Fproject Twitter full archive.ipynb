{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Collecting searchtweets\n",
      "  Downloading searchtweets-1.7.6-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from searchtweets) (2.22.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from searchtweets) (5.3)\n",
      "Collecting tweet-parser\n",
      "  Using cached tweet_parser-1.13.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->searchtweets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->searchtweets) (1.25.8)\n",
      "Installing collected packages: tweet-parser, searchtweets\n",
      "Successfully installed searchtweets-1.7.6 tweet-parser-1.13.2\n"
     ]
    }
   ],
   "source": [
    "#Libraries Required\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except ModuleNotFoundError:\n",
    "    !pip install yaml\n",
    "    import yaml\n",
    "    \n",
    "try:\n",
    "    import json\n",
    "except ModuleNotFoundError:\n",
    "    !pip install json\n",
    "    import json\n",
    "\n",
    "try:\n",
    "    import re\n",
    "except ModuleNotFoundError:\n",
    "    !pip install re\n",
    "    import re\n",
    "\n",
    "try:\n",
    "    import math\n",
    "except ModuleNotFoundError:\n",
    "    !pip install math\n",
    "    import math\n",
    "\n",
    "try:\n",
    "    from datetime import date\n",
    "    from datetime import timedelta\n",
    "except ModuleNotFoundError:\n",
    "    !pip install datetime\n",
    "    from datetime import date\n",
    "    from datetime import timedelta\n",
    "    \n",
    "try:\n",
    "    from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "except ModuleNotFoundError:\n",
    "    !pip install searchtweets\n",
    "    from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "\n",
    "try:\n",
    "    import time\n",
    "except ModuleNotFoundError:\n",
    "    !pip install time\n",
    "    import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2020-09-03.jsonl\n",
      "2020-09-04.jsonl\n",
      "2020-09-05.jsonl\n",
      "2020-09-06.jsonl\n",
      "2020-09-07.jsonl\n",
      "2020-09-08.jsonl\n",
      "2020-09-09.jsonl\n",
      "2020-09-10.jsonl\n",
      "2020-09-11.jsonl\n",
      "2020-09-12.jsonl\n",
      "2020-09-13.jsonl\n",
      "2020-09-14.jsonl\n",
      "2020-09-15.jsonl\n",
      "2020-09-16.jsonl\n",
      "2020-09-17.jsonl\n",
      "2020-09-18.jsonl\n",
      "2020-09-19.jsonl\n",
      "2020-09-20.jsonl\n",
      "2020-09-21.jsonl\n",
      "2020-09-22.jsonl\n",
      "2020-09-23.jsonl\n",
      "2020-09-24.jsonl\n",
      "2020-09-25.jsonl\n",
      "2020-09-26.jsonl\n",
      "2020-09-27.jsonl\n",
      "2020-09-28.jsonl\n",
      "2020-09-29.jsonl\n",
      "2020-09-30.jsonl\n",
      "2020-10-01.jsonl\n",
      "2020-10-02.jsonl\n",
      "2020-10-03.jsonl\n",
      "2020-10-04.jsonl\n",
      "2020-10-05.jsonl\n",
      "2020-10-06.jsonl\n",
      "2020-10-07.jsonl\n",
      "2020-10-08.jsonl\n",
      "2020-10-09.jsonl\n",
      "2020-10-10.jsonl\n",
      "2020-10-11.jsonl\n",
      "2020-10-12.jsonl\n",
      "2020-10-13.jsonl\n",
      "2020-10-14.jsonl\n",
      "2020-10-15.jsonl\n",
      "2020-10-16.jsonl\n",
      "2020-10-17.jsonl\n",
      "2020-10-18.jsonl\n",
      "2020-10-19.jsonl\n",
      "2020-10-20.jsonl\n",
      "2020-10-21.jsonl\n",
      "2020-10-22.jsonl\n",
      "2020-10-23.jsonl\n",
      "2020-10-24.jsonl\n",
      "2020-10-25.jsonl\n",
      "2020-10-26.jsonl\n",
      "2020-10-27.jsonl\n",
      "2020-10-28.jsonl\n",
      "2020-10-29.jsonl\n",
      "2020-10-30.jsonl\n",
      "2020-10-31.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "import yaml\n",
    "import math\n",
    "import glob\n",
    "\n",
    "apikeys=[]\n",
    "apisecretkeys=[]\n",
    "apidevlabels=[]\n",
    "dates=[]\n",
    "\n",
    "startdate=datetime.datetime(2020, 9, 1)\n",
    "enddate=datetime.datetime(2020,10,31)\n",
    "#print(startdate.strftime(\"%Y-%m-%d\"))\n",
    "curdate=startdate\n",
    "\n",
    "while curdate!= enddate:\n",
    "    dates.append(curdate)\n",
    "    curdate = curdate + timedelta(days=1)\n",
    "    \n",
    "dates.append(enddate)\n",
    "\n",
    "#divyansh\n",
    "apikeys.append('ajz4KbqskMTtIBbIroaM7yoFc')\n",
    "apisecretkeys.append('e2Z0JuoVjjKj0yGyHlKPKwK0thulkTxV0ufiBkcIzo6XcHzv0g')\n",
    "apidevlabels.append('submission1')\n",
    "#raj\n",
    "apikeys.append('ajz4KbqskMTtIBbIroaM7yoFc')\n",
    "apisecretkeys.append('e2Z0JuoVjjKj0yGyHlKPKwK0thulkTxV0ufiBkcIzo6XcHzv0g')\n",
    "apidevlabels.append('submission1')\n",
    "#aparna\n",
    "apikeys.append('ajz4KbqskMTtIBbIroaM7yoFc')\n",
    "apisecretkeys.append('e2Z0JuoVjjKj0yGyHlKPKwK0thulkTxV0ufiBkcIzo6XcHzv0g')\n",
    "apidevlabels.append('submission1')\n",
    "#abhilash\n",
    "apikeys.append('ajz4KbqskMTtIBbIroaM7yoFc')\n",
    "apisecretkeys.append('e2Z0JuoVjjKj0yGyHlKPKwK0thulkTxV0ufiBkcIzo6XcHzv0g')\n",
    "apidevlabels.append('submission1')\n",
    "\n",
    "\n",
    "apikeys=[]  #comment out after getting keys\n",
    "\n",
    "\n",
    "\n",
    "SEARCH_QUERY = '@realDonaldTrump has:geo place_country:US'\n",
    "RESULTS_PER_CALL = 100\n",
    "API_SCOPE = 'fullarchive'\n",
    "\n",
    "\n",
    "\n",
    "donedates = glob.glob(\"*.jsonl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "totalrequestspossible = len(apikeys)*50\n",
    "requestsperday = math.floor(totalrequestspossible/len(dates))\n",
    "print(requestsperday)\n",
    "\n",
    "for i in range(len(apikeys)):\n",
    "    config = dict(\n",
    "                    search_tweets_api=dict(\n",
    "                    account_type='premium',\n",
    "                    endpoint=f\"https://api.twitter.com/1.1/tweets/search/{API_SCOPE}/{apidevlabels[i]}.json\",\n",
    "                    consumer_key=apikeys[i],\n",
    "                    consumer_secret=apisecretkeys[i]\n",
    "                    )\n",
    "                    )\n",
    "    with open('twitter_keys.yaml', 'w') as config_file:\n",
    "        yaml.dump(config, config_file, default_flow_style=False) \n",
    "    for j in range(len(dates)):\n",
    "        TO_DATE = dates[j].strftime(\"%Y-%m-%d\")\n",
    "        FROM_DATE = dates[j].strftime(\"%Y-%m-%d\")\n",
    "        FILENAME = f'{TO_DATE}.jsonl'\n",
    "        if FILENAME in donedates:\n",
    "            continue\n",
    "        print(FILENAME)\n",
    "        for k in range(requestsperday):\n",
    "            rule = gen_rule_payload(SEARCH_QUERY,\n",
    "                        results_per_call=RESULTS_PER_CALL,\n",
    "                        from_date=FROM_DATE,\n",
    "                        to_date=TO_DATE,\n",
    "                        )\n",
    "\n",
    "            rs = ResultStream(rule_payload=rule,\n",
    "                                  max_results=MAX_RESULTS,\n",
    "                                      **premium_search_args)\n",
    "\n",
    "            with open(FILENAME, 'a', encoding='utf-8') as f:\n",
    "                n = 0\n",
    "                for tweet in rs.stream():\n",
    "                    n += 1\n",
    "                    if n % PRINT_AFTER_X == 0:\n",
    "                        print('{0}: {1}'.format(str(n), tweet['created_at']))\n",
    "                    json.dump(tweet, f)\n",
    "                    f.write('\\n')\n",
    "                    print('done')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
