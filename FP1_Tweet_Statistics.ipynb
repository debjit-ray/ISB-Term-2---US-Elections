{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T12:21:08.640132Z",
     "start_time": "2020-12-20T12:21:00.827945Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the sentiment file for the tweets collected from US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T12:21:11.308252Z",
     "start_time": "2020-12-20T12:21:08.642129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>truncated</th>\n",
       "      <th>url</th>\n",
       "      <th>location_US_State</th>\n",
       "      <th>geo_US_State</th>\n",
       "      <th>place_US_State</th>\n",
       "      <th>createDate</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>TB_polarity</th>\n",
       "      <th>TB_subjectivity</th>\n",
       "      <th>AF_polarity</th>\n",
       "      <th>TB_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217234682309464064</td>\n",
       "      <td>2020-01-14T23:58:58</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1217197393948692482</td>\n",
       "      <td>2020-01-14T21:30:47</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2 things are often true there is enough evide...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217197457270104066</td>\n",
       "      <td>2020-01-14T21:31:02</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/5R55ma3Efz]</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Whether you are a Democrat or Republican Trump...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1217197459857866753</td>\n",
       "      <td>2020-01-14T21:31:03</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>pubs You don t say Trump Adviser Caught on Ta...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1217197467441213441</td>\n",
       "      <td>2020-01-14T21:31:05</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>So the shooting in Pensacola WAS a terrorist ...</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>Strongly Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  truncated  \\\n",
       "0  1217234682309464064  2020-01-14T23:58:58      False   \n",
       "1  1217197393948692482  2020-01-14T21:30:47      False   \n",
       "2  1217197457270104066  2020-01-14T21:31:02       True   \n",
       "3  1217197459857866753  2020-01-14T21:31:03      False   \n",
       "4  1217197467441213441  2020-01-14T21:31:05      False   \n",
       "\n",
       "                         url location_US_State geo_US_State place_US_State  \\\n",
       "0                         []     New Hampshire          NaN            NaN   \n",
       "1                         []           Florida          NaN            NaN   \n",
       "2  [https://t.co/5R55ma3Efz]        New Jersey          NaN            NaN   \n",
       "3                         []          Virginia          NaN            NaN   \n",
       "4                         []             Texas          NaN            NaN   \n",
       "\n",
       "   createDate                                          clean_txt  TB_polarity  \\\n",
       "0  2020-01-14   A PROVEN LIAR Trump said HE D PAY LEGAL FEES ...         0.20   \n",
       "1  2020-01-14   2 things are often true there is enough evide...         0.45   \n",
       "2  2020-01-14  Whether you are a Democrat or Republican Trump...         0.00   \n",
       "3  2020-01-14   pubs You don t say Trump Adviser Caught on Ta...         0.00   \n",
       "4  2020-01-14   So the shooting in Pensacola WAS a terrorist ...        -0.80   \n",
       "\n",
       "   TB_subjectivity  AF_polarity       TB_sentiment  \n",
       "0         0.200000         -5.0            Neutral  \n",
       "1         0.716667          5.0           Positive  \n",
       "2         0.000000          1.0            Neutral  \n",
       "3         0.000000         -2.0            Neutral  \n",
       "4         1.000000         -3.0  Strongly Negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UStweets = pd.read_csv(\"Data Dump\\CleanTweets\\FP1_Merged_US_Sentiments.csv\")\n",
    "UStweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For some of the tweets, the location is at a County level, find the corresponding state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T12:21:11.314236Z",
     "start_time": "2020-12-20T12:21:11.310246Z"
    }
   },
   "outputs": [],
   "source": [
    "def fncFindStateByCoordinates(geo):\n",
    "    geolocator = Nominatim(user_agent =\"FP1_Convert_Tweets\")\n",
    "    location = geolocator.geocode(geo)\n",
    "    if str(location).split(',')[-1] ==\" United States\":\n",
    "        state = str(location).split(',')[-2].strip()\n",
    "    return state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tweets had three location attributes - geo, place and location. Identify, which of these is the valid one to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.831Z"
    }
   },
   "outputs": [],
   "source": [
    "stateList = []\n",
    "for iRow in range(len(UStweets)):\n",
    "    state = \"\"\n",
    "    location = (UStweets.iloc[iRow]['location_US_State'])\n",
    "    geo = (UStweets.iloc[iRow]['geo_US_State'])\n",
    "    place = (UStweets.iloc[iRow]['place_US_State'])\n",
    "    if (str(geo).endswith(\"County\")):\n",
    "        geo = fncFindStateByCoordinates(str(geo))\n",
    "    if ((str(geo) != \"nan\")):\n",
    "        state = str(geo)\n",
    "    elif ((str(place) != \"nan\") and (str(place) != \"United States of America\")):\n",
    "        state = str(place)\n",
    "    elif ((str(location) != \"United States of America\")): \n",
    "        state = str(location)\n",
    "    else:\n",
    "        state = \"\"\n",
    "    if str(state) == \"nan\":\n",
    "        state = \"\"\n",
    "    stateList.append(state)\n",
    "UStweets['State'] = pd.Series(stateList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Election Results to identify the states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.832Z"
    }
   },
   "outputs": [],
   "source": [
    "Results = pd.read_csv(\"Data Dump\\FP1_2020_USElections_StateResults_1126.txt\", header= None, \n",
    "                      names = ['State','Tot_Population', 'FirstName', 'LastName', 'Party', 'VoteCount'],\n",
    "                      dtype={'State': str, 'Tot_Population': int, 'FirstName': str, 'LastName': str, 'Party': str, 'VoteCount':int}\n",
    "                     )\n",
    "Results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter only the rows for Trump\n",
    "TrumpVotes = Results[Results['LastName'] == 'Trump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the USTweets, filter the rows that correspond to the states in the election results\n",
    "##### There are some tweets from the Union Territorries which did not participate in the Election. Also, some tweets from US, which could not be mapped to specific states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.838Z"
    }
   },
   "outputs": [],
   "source": [
    "USStateTweets = UStweets[UStweets['State'].isin(list(TrumpVotes['State']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.840Z"
    }
   },
   "outputs": [],
   "source": [
    "len(USStateTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For calculating the numbers at the country level, create new dataframe with all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.842Z"
    }
   },
   "outputs": [],
   "source": [
    "CountryTweets = UStweets\n",
    "CountryTweets['State'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.844Z"
    }
   },
   "outputs": [],
   "source": [
    "len(CountryTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the 2 dataframes - one at the State level and the other at Country level, to form the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.846Z"
    }
   },
   "outputs": [],
   "source": [
    "finalTweets = USStateTweets.append(CountryTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.847Z"
    }
   },
   "outputs": [],
   "source": [
    "len(finalTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe for Statistical Model and remove all unwanted columns.\n",
    "##### US Presidential Elections 2020 was held on 3rd November 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.849Z"
    }
   },
   "outputs": [],
   "source": [
    "def fncFindLimits(tweetDF, preElectionInd, sentimentInd):\n",
    "    # Group the data by State and Sentiment while taking the mean for the polarity and subjectivity scores, and summing up the count of tweets\n",
    "    tweetStats = tweetDF[tweetDF['preElection'] == preElectionInd].groupby(['State', sentimentInd]).agg({'TB_polarity':np.mean, 'AF_polarity':np.mean, 'TB_subjectivity':np.mean, 'id': np.size}).sort_values(['State', sentimentInd])\n",
    "    # Make the dataframe flat by removing the index\n",
    "    tweetStats.reset_index(inplace=True)\n",
    "    # Calculate the total sample size per state\n",
    "    stateSampleSize = dict(tweetDF[tweetDF['preElection'] == preElectionInd].groupby(['State'])['id'].count())\n",
    "    # Populate the statewise sample size\n",
    "    tweetStats['State_SampleSize'] = tweetStats['State'].apply(lambda x: stateSampleSize.get(x))\n",
    "    # Rename the columns to more meaningful\n",
    "    tweetStats.columns = [['State',sentimentInd,'TB_polarity','AF_polarity','TB_subjectivity','Count','State_SampleSize']]\n",
    "    # Calculate the proportion for each sentiment per state\n",
    "    calcPct = lambda row : (int(row['Count'])/int(row['State_SampleSize']))\n",
    "    tweetStats['Sample_sentiment_Pct'] = tweetStats.apply(lambda row: calcPct(row), axis=1)\n",
    "    # Using Central Limit Theorem calculate the sample error\n",
    "    calcError = lambda row : (st.norm.ppf(confInt) * math.sqrt(row['Sample_sentiment_Pct'] * (1 - row['Sample_sentiment_Pct'])/int(row['State_SampleSize'])))\n",
    "    tweetStats['Sample_Error'] = tweetStats.apply(lambda row: calcError(row), axis=1)\n",
    "    # Calculate the lower and upper limit for a 95% confidence interval for the population\n",
    "    calcLCL = lambda row : row['Sample_sentiment_Pct'] - calcError(row)\n",
    "    tweetStats['LCL'] = tweetStats.apply(lambda row:calcLCL(row), axis = 1)\n",
    "    calcUCL = lambda row : row['Sample_sentiment_Pct'] + calcError(row)\n",
    "    tweetStats['UCL'] = tweetStats.apply(lambda row:calcUCL(row), axis = 1)\n",
    "    return(tweetStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.851Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confInt = 0.95\n",
    "# Retain only the required columns\n",
    "forStats = finalTweets[['id','createDate','State','TB_polarity','TB_subjectivity','AF_polarity','TB_sentiment']]\n",
    "# We are interested in only the data from Sep 01, 2020\n",
    "forStats = forStats[forStats['createDate'] > '2020-08-30']\n",
    "# Add a column to identify whether the data is pre or post election\n",
    "forStats['preElection'] = forStats['createDate'].apply(lambda x: 'Y' if (x <= '2020-11-03') else 'N')\n",
    "\n",
    "preElectionStats = fncFindLimits(forStats, \"Y\", 'TB_sentiment')\n",
    "postElectionStats = fncFindLimits(forStats, \"N\", 'TB_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.854Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preElectionStats = fncFindLimits(forStats, \"Y\", 'TB_sentiment')\n",
    "postElectionStats = fncFindLimits(forStats, \"N\", 'TB_sentiment')\n",
    "preElectionStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.856Z"
    }
   },
   "outputs": [],
   "source": [
    "postElectionStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.857Z"
    }
   },
   "outputs": [],
   "source": [
    "UStweets['AF_polarity'].sort_values().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.858Z"
    }
   },
   "outputs": [],
   "source": [
    "UStweets['AF_polarity'].sort_values().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.860Z"
    }
   },
   "outputs": [],
   "source": [
    "preElectionStats.to_csv(\"Data Dump\\FP1_2020_Tweet_StatsModel_PreElection-1.csv\", index = None)\n",
    "postElectionStats.to_csv(\"Data Dump\\FP1_2020_Tweet_StatsModel_PostElection-1.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.862Z"
    }
   },
   "outputs": [],
   "source": [
    "UStweets[UStweets['TB_sentiment'] == 'Neutral'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.863Z"
    }
   },
   "outputs": [],
   "source": [
    "fncFindSentiment = lambda x: \"Strongly Negative\" if float(x) <= -0.60 else (\"Negative\" if float(x) <= -0.10 else (\"Neutral\" if float(x) <= 0.10 else (\"Positive\" if float(x) <= 0.60 else \"Strongly Positive\")))\n",
    "forStats['TB_sentiment'] = forStats['TB_polarity'].apply(fncFindSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-20T12:21:00.864Z"
    }
   },
   "outputs": [],
   "source": [
    "preElec = forStats[forStats['preElection']=='Y']\n",
    "temp = preElec.groupby(['State']).agg({'TB_polarity':np.mean, 'AF_polarity':np.mean})\n",
    "temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
